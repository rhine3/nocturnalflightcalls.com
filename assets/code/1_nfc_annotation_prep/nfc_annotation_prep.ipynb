{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare NFC annotations\n",
    "\n",
    "This notebook\n",
    "* Uses the NFC annotation files that Lauren Chronister cleaned (`clean_nfcs_lmc_fall2021/Annotations_cleaned`)\n",
    "* Pairs annotation files with sound files, including modifying the names of some annotation files for consistency and saving them in a new folder (`./kearney-nfc_annotations_cleaned`)\n",
    "* Loads a table of preliminary frequency information, guessed manually and stored in `freqs_and_durations_draft.csv`. (The codes in this table were created by finding all the codes using `0_nfc_finding.ipynb`).\n",
    "* Extracts some preliminary information about the lengths of each species's calls and adds it to the previously loaded `freqs_and_durations_draft.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "from opensoundscape.helpers import run_command\n",
    "from opensoundscape.audio import Audio\n",
    "from opensoundscape.spectrogram import Spectrogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get cleaned annotations\n",
    "Got the zip file from Lauren and unzipped them in this folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get list of species to extract\n",
    "\n",
    "This is in Lauren's `clean_nfcs_lmc_fall2021/master_key.csv`.\n",
    "\n",
    "Column meaning:\n",
    "\n",
    "* Code = the code from the original annotation\n",
    "* New_Code = Corrected code that includes clade and any needed corrections\n",
    "* Check: \n",
    "  * \"yes\" = is good\n",
    "  * \"uncertain\" = we're not sure what they annotator was going for; these were dropped\n",
    "  * some other value = something that was updated through a check\n",
    "* Count = the number of annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code</th>\n",
       "      <th>New_Code</th>\n",
       "      <th>Check</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALAUDIDAE-EREMOPHILA-ALPESTRIS-HOLA</td>\n",
       "      <td>PASSERIFORMES-ALAUDIDAE-EREMOPHILA-ALPESTRIS-HOLA</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ANATIDAE-ANAS-CRECCA-GWTE</td>\n",
       "      <td>ANSERIFORMES-ANATIDAE-ANAS-CRECCA-GWTE</td>\n",
       "      <td>yes</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ANATIDAE-BRANTA-CANADENSIS-CAGO</td>\n",
       "      <td>ANSERIFORMES-ANATIDAE-BRANTA-CANADENSIS-CANG</td>\n",
       "      <td>yes</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ANATIDAE-BUCEPHALA-CLANGULA-COGE</td>\n",
       "      <td>ANSERIFORMES-ANATIDAE-BUCEPHALA-CLANGULA-COGO</td>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ANATIDAE-CLANGULA-HYEMALIS-LTDU</td>\n",
       "      <td>ANSERIFORMES-ANATIDAE-CLANGULA-HYEMALIS-LTDU</td>\n",
       "      <td>yes</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Code  \\\n",
       "0  ALAUDIDAE-EREMOPHILA-ALPESTRIS-HOLA   \n",
       "1            ANATIDAE-ANAS-CRECCA-GWTE   \n",
       "2      ANATIDAE-BRANTA-CANADENSIS-CAGO   \n",
       "3     ANATIDAE-BUCEPHALA-CLANGULA-COGE   \n",
       "4      ANATIDAE-CLANGULA-HYEMALIS-LTDU   \n",
       "\n",
       "                                            New_Code Check  Count  \n",
       "0  PASSERIFORMES-ALAUDIDAE-EREMOPHILA-ALPESTRIS-HOLA   yes      1  \n",
       "1             ANSERIFORMES-ANATIDAE-ANAS-CRECCA-GWTE   yes     29  \n",
       "2       ANSERIFORMES-ANATIDAE-BRANTA-CANADENSIS-CANG   yes    148  \n",
       "3      ANSERIFORMES-ANATIDAE-BUCEPHALA-CLANGULA-COGO   yes      2  \n",
       "4       ANSERIFORMES-ANATIDAE-CLANGULA-HYEMALIS-LTDU   yes     40  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = pd.read_csv(\"../../../annotations/clean_nfcs_lmc_fall2021/master_key.csv\")\n",
    "counts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get 4-letter alpha codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts['alpha'] = counts.Code.str.split('-', expand=True)[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exclude uncertain ones and ones where there is no species based on whether or not the alpha code is 4 characters (e.g. ANATIDAE, NA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = counts.query('Check != \"uncertain\"') # remove ones where we weren't sure what the annotators were going for\n",
    "counts = counts[counts.alpha.str.len() == 4] # remove non-4 letters\n",
    "counts = counts.query('alpha != \"UNKN\"') # remove ones that the annotators marked as unknown\n",
    "counts = counts.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_by_alpha = counts.groupby('alpha').Count.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get list of alpha codes to extract annotations for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(counts_by_alpha.index.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match up annotation and sound files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Annotations are located in `clean_nfcs/Annotations_cleaned` and are `.txt` files with the following columns:\n",
    "```\n",
    "Begin time (s)\tEnd time (s)\tLow freq (hz)\tHigh freq (hz)\tOrder\tFamily\tGenus\tSpecies\tAlpha code\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get list of files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2318"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selection_tables = glob('../../../annotations/clean_nfcs_lmc_fall2021/Annotations_cleaned/*.txt')\n",
    "selection_tables.sort(key=lambda x: Path(x).name)\n",
    "len(selection_tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Audio files are located in `/bgfs/jkitzes/ter38/data/kearney-nfc`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235126"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames = list(Path('/bgfs/jkitzes/ter38/data/kearney-nfc/').rglob('*.wav'))\n",
    "filenames.sort(key=lambda x: Path(x).name)\n",
    "len(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_stems = [Path(t).stem for t in filenames]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get an abbreviated list of sound files that have a selection table associated with them so that it doesn't take as long to make the dictionary below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_stems = [Path(t).stem for t in selection_tables]\n",
    "to_keep = []\n",
    "for idx, filename in enumerate(filenames):\n",
    "    if filename.stem in table_stems:\n",
    "        to_keep.append(idx)\n",
    "sound_files = [filenames[i] for i in to_keep]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create new set of filename-fixed annotation files\n",
    "\n",
    "Inspect the lengths of the matched arrays and see..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2318"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(selection_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1229"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sound_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...that sound files weren't found for many selection tables. We'll have to find which ones those are and fix the names of the annotation tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_annot_path = Path('kearney-nfc_annotations_cleaned')\n",
    "cleaned_annot_path.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dictionary matching the selection tables we already have with the necessary audio files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/bgfs/jkitzes/ter38/data/kearney-nfc/Amherst Study 2014-2015/Amherst Access Road/A2AR1_20140504_210100.wav')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Path(sound_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables_to_filenames = {}\n",
    "need_to_fix_names = []\n",
    "\n",
    "# For all the selection tables\n",
    "for selection_table in selection_tables:\n",
    "    \n",
    "    # Search through the list of audio files to find one with a \n",
    "    # filename matching this selection table\n",
    "    for idx, sound_file in enumerate(sound_files):\n",
    "        if Path(sound_file).stem == Path(selection_table).stem:\n",
    "            new_annotation_filename = cleaned_annot_path.joinpath(Path(selection_table).name)\n",
    "            shutil.copy(str(selection_table), str(new_annotation_filename))\n",
    "            tables_to_filenames[Path(selection_table).name] = str(sound_file)\n",
    "            break\n",
    "            \n",
    "    # If we haven't found a matching audio filename in the loop above,\n",
    "    # take note to change the name\n",
    "    if Path(selection_table).name not in tables_to_filenames.keys():\n",
    "        need_to_fix_names.append(selection_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1089"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(need_to_fix_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../../annotations/clean_nfcs_lmc_fall2021/Annotations_cleaned/BERI1_20180805_211600.txt',\n",
       " '../../../annotations/clean_nfcs_lmc_fall2021/Annotations_cleaned/BERI1_20180806_211500.txt',\n",
       " '../../../annotations/clean_nfcs_lmc_fall2021/Annotations_cleaned/BERI1_20180807_211300.txt',\n",
       " '../../../annotations/clean_nfcs_lmc_fall2021/Annotations_cleaned/BERI1_20180808_211200.txt',\n",
       " '../../../annotations/clean_nfcs_lmc_fall2021/Annotations_cleaned/BERI1_20180809_211000.txt']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "need_to_fix_names[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the names that need to be fixed are problematic because the selection tables and audio files are these two styles:\n",
    "* Selection table: `BERI1_20180805_211600.txt`\n",
    "* Audio file: `BERI1-20180805_211600.txt`\n",
    "\n",
    "Others are problematic because they have two underscores instead of one in one place.\n",
    "\n",
    "Change this for all of the files in the `need_to_fix_names` list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposed_new_names = {}\n",
    "\n",
    "for need_to_fix_name in need_to_fix_names:\n",
    "    name = Path(need_to_fix_name).name.replace('__', '_') # Fix the two-underscore typo\n",
    "    parts = name.split('_')\n",
    "    new_name = parts[0] + '-' + parts[1] + '_' + parts[2] # Fix the underscore-instead-of-hyphen typo\n",
    "    new_annotation_filename = cleaned_annot_path.joinpath(new_name)\n",
    "    proposed_new_names[need_to_fix_name] = new_annotation_filename\n",
    "    #shutil.copy(need_to_fix_name, new_name)\n",
    "    #fixed_names.append(new_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1089"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(proposed_new_names.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new list of sound files that correspond to the fixed names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1087"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_stems_fixed = [Path(t).stem for t in proposed_new_names.values()]\n",
    "to_keep = []\n",
    "for idx, filename in enumerate(filenames):\n",
    "    if filename.stem in table_stems_fixed:\n",
    "        to_keep.append(idx)\n",
    "sound_files = [filenames[i] for i in to_keep] \n",
    "len(sound_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have found 1087 sound files of the 1089 selection tables--pretty close.\n",
    "\n",
    "Add correspondence between the newly fixed names to the master dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "need_to_fix_names = []\n",
    "\n",
    "# For all the proposed fixes\n",
    "for old_annotation_filename, new_annotation_filename in proposed_new_names.items():\n",
    "    \n",
    "    # Search through the list of audio files to find one with a \n",
    "    # filename matching this selection table\n",
    "    for idx, sound_file in enumerate(sound_files):\n",
    "        if Path(sound_file).stem == new_annotation_filename.stem:\n",
    "            shutil.copy(str(old_annotation_filename), str(new_annotation_filename))\n",
    "            tables_to_filenames[Path(new_annotation_filename).name] = str(sound_file)\n",
    "            break\n",
    "            \n",
    "    # If we haven't found a matching audio filename in the loop above,\n",
    "    # take note to change the name\n",
    "    if new_annotation_filename.name not in tables_to_filenames.keys():\n",
    "        need_to_fix_names.append(selection_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the two remaining names?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../../annotations/clean_nfcs_lmc_fall2021/Annotations_cleaned/SWWB_20161020_183900.txt',\n",
       " '../../../annotations/clean_nfcs_lmc_fall2021/Annotations_cleaned/SWWB_20161020_183900.txt']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "need_to_fix_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After looking through the original dataset I cannot find audio files corresponding to these names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the correspondence betwen selection tables and audio files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, val in tables_to_filenames.items():\n",
    "    tables_to_filenames[key] = [val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_audio_pairs = pd.DataFrame(tables_to_filenames).transpose().reset_index()\n",
    "annotation_audio_pairs.columns = ['annotation_file', 'audio_file']\n",
    "annotation_audio_pairs.to_csv('annotation_audio_pairs.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get duration information for NFCs\n",
    "\n",
    "We created a file called `freqs_and_durations_draft.csv` which contains the expected frequencies for each of the species in the dataset. Now let's add the duration information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_annot_path = Path('kearney-nfc_annotations_cleaned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kearney-nfc_annotations_cleaned/A2PS1_20140418_203900.txt\n",
      "kearney-nfc_annotations_cleaned/A2WA_20150509_210800.txt\n",
      "kearney-nfc_annotations_cleaned/BRIS1_20180901_203200.txt\n",
      "kearney-nfc_annotations_cleaned/BRIS1_20180901_203200.txt\n",
      "kearney-nfc_annotations_cleaned/BRIS1_20180901_203200.txt\n",
      "kearney-nfc_annotations_cleaned/CAFO1_20170916_200200.txt\n",
      "kearney-nfc_annotations_cleaned/CAFO1_20180423_204800.txt\n",
      "kearney-nfc_annotations_cleaned/CAFO1_20180423_204800.txt\n",
      "kearney-nfc_annotations_cleaned/SWSG_20131003_191000.txt\n",
      "kearney-nfc_annotations_cleaned/SWWB_20160906_200200.txt\n",
      "kearney-nfc_annotations_cleaned/SWWB_20160906_200200.txt\n",
      "kearney-nfc_annotations_cleaned/SWWB_20160906_200200.txt\n",
      "kearney-nfc_annotations_cleaned/SWWB_20160906_200200.txt\n",
      "kearney-nfc_annotations_cleaned/SWWB_20160906_200200.txt\n",
      "kearney-nfc_annotations_cleaned/SWWB_20160906_200200.txt\n",
      "kearney-nfc_annotations_cleaned/BERI1-20190902_202900.txt\n",
      "kearney-nfc_annotations_cleaned/CAWRR-20151106_173800.txt\n",
      "kearney-nfc_annotations_cleaned/SWGH-20150524_211200.txt\n"
     ]
    }
   ],
   "source": [
    "lengths_dict = {}\n",
    "for txt_file, audio_file in list(tables_to_filenames.items()):\n",
    "    txt_filename = cleaned_annot_path.joinpath(txt_file)\n",
    "    df = pd.read_csv(txt_filename, sep='\\t')\n",
    "    for idx, row in df.iterrows():\n",
    "        alpha = row['Alpha code']\n",
    "        if alpha in [\"BLGR\", \"BRCR\", \"COGO\", \"EVGR\", \"LALO\", \"OROR\", \"RBGU\", \"SORA\", \"STSA\"]:\n",
    "            print(txt_filename)\n",
    "        # Skip rows where alpha code was unknown or not able to be determined\n",
    "        if alpha == '?':\n",
    "            continue\n",
    "        length = row[\"End time (s)\"] - row['Begin time (s)']\n",
    "        if alpha not in lengths_dict.keys():\n",
    "            lengths_dict[alpha] = [length]\n",
    "        else:\n",
    "            lengths_dict[alpha].append(length)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Round durations and save to CSV ***OUTDATED***\n",
    "\n",
    "Use a basic ceiling rounder to assign each sound type to one of four lengths. These will be modified by later scripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'break' outside loop (<ipython-input-43-6aaf1f276005>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-43-6aaf1f276005>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'break' outside loop\n"
     ]
    }
   ],
   "source": [
    "break # THIS CODE IS OUTDATED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "freq_limits = pd.read_csv(\"../freqs_and_durations_draft.csv\", usecols=['code', 'low_freq', 'high_freq'])\n",
    "codes = freq_limits.code.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the question mark (unknown code) - doesn't exist because we already removed it from the freq_limits df."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#codes.sort()\n",
    "#assert codes[0] == '?'\n",
    "#codes = codes[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def ceiling_rounder(\n",
    "    in_number,\n",
    "    acceptable_numbers = [0.05, 0.1, 0.15, 0.5]):\n",
    "    \"\"\"Perform ceiling rounding of a number to one of a list of numbers. \n",
    "    \n",
    "    Handles np.nan by returning 0.1.\n",
    "    \"\"\"\n",
    "    acceptable_numbers.sort()\n",
    "    if np.isnan(in_number):\n",
    "        return 0.1\n",
    "    for acceptable_number in acceptable_numbers:\n",
    "        if in_number <= acceptable_number:\n",
    "            return acceptable_number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "\n",
    "freq_limits.sort_values('code', inplace=True)\n",
    "\n",
    "species_lengths = []\n",
    "for code in freq_limits.code.tolist():\n",
    "    ls = lengths_dict[code]\n",
    "    species_lengths.append(np.round(np.median(np.array(ls)), decimals=3))\n",
    "\n",
    "freq_limits['median_duration'] = species_lengths\n",
    "freq_limits['approx_duration'] = [ceiling_rounder(l) for l in species_lengths]\n",
    "\n",
    "freq_limits.to_csv('freqs_and_durations_draft.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opso_dev",
   "language": "python",
   "name": "opso_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
